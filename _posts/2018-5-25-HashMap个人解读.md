---

layout: post

title: HashMap个人解读

date: 2018-5-25

tags: Java基础

---



## HashMap个人解读

本文基于JDK 1.8
### 本文目录
- 确定哈希桶数组索引位置
- put方法的详细执行
- 树化
- 扩容过程
- 线程安全性
- JDK1.8与JDK1.7的性能对比
- 小结
- 解决哈希冲突的常用方法


### 确定哈希桶数组索引位置



- HashMap中增加、删除、查找元素的源码如下：

```java

public V put(K key, V value) {

        return putVal(hash(key), key, value, false, true);

    }

public V remove(Object key) {

        Node<K,V> e;

        return (e = removeNode(hash(key), key, null, false, true)) == null ?

            null : e.value;

    }

public V get(Object key) {

        Node<K,V> e;

        return (e = getNode(hash(key), key)) == null ? null : e.value;

    }

```

这三个最具代表性的方法中都使用到了HashMap的核心方法`hash(key)`，这个方法包含了HashMap最核心的部分——由key值确定键值对(`Node<K,V>`)在hash桶数组的位置。



- HashMap的数据结构是数组和链表以及红黑树的结合，所以使用者当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，才能获得最大的查询的效率。

- HashMap定位数组索引位置，直接决定了hash方法的离散性能。`hash()`方法的源码如下：

```java

//jdk1.8 & jdk1.7

static final int hash(Object key) {

        int h;

        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);

    }

//jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的

static int indexFor(int h, int length) {

     return h & (length-1);

}

```

其中`h = key.hashCode()`为第一步取hashCode值，调用的hashCode()是一个native方法, `h ^ (h >>> 16)`为第二步高位参与运算，`h & (length-1)`第三步为取模运算。



- Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。

- 对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。

- 我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，模运算的消耗还是比较大的，在HashMap中是这样做的：调用第三步来计算该对象应该保存在table数组的哪个索引处。

	- 通过`h & (table.length -1)`来得到该对象的保存位;

	- HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化

	- 如果length总是2的n次方时，`h& (length-1)`就运算等价于对length取模，也就是h%length，但是&比%具有更高的效率

- 在JDK1.8的实现中，优化了高位运算的算法

	- 通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h >>> 16)

	- 这么做主要是从速度、功效、质量来考虑的，这么做可以在`Node<k,v>`数组table的length比较小的时候，也能保证考虑到高低Bit都参与到Hash的计算中，同时不会有太大的开销。示例如下图：

![hashMap哈希算法例图](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap哈希算法例图.png)

<b>拓展</b>

```

^在Java中是求异或的运算符

<<，左移运算符，num << 1,相当于num乘以2

>>，右移运算符，num >> 1,相当于num除以2

>>>，无符号右移，忽略符号位，空位都以0补齐

```

### put方法的详细执行

HashMap的put方法执行过程可以通过下图来理解：

![hashMap put方法执行流程图](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap put方法执行流程图.png)

1. 判断键值对数组table[i]是否为空或为null;

	- 如果为空或null，执行resize()进行扩容；

	- 不为空则转向②

2. 根据键值key计算hash值得到插入的数组索引i；

	- 如果table[i]==null，直接新建节点添加，转向⑥；

	- 如果table[i]不为空，转向③；

3. 判断table[i]的首个元素是否和key一样；

	- 如果相同直接覆盖value；

	- 如果不同，转向④，这里的相同指的是hashCode以及equals；

4. 判断table[i] 是否为treeNode，即table[i]是否是红黑树；

	- 如果是红黑树，则直接在树中插入键值对；

	- 如果不为红黑树，转向⑤；

5. 遍历table[i]，判断链表长度是否大于8；

	- 大于8的话把链表转换为红黑树，在红黑树中执行插入操作；

	- 否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；

6. 插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold；

	- 如果超过，进行扩容；

- JDK1.8HashMap的put方法源码如下:

```java
public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        // 步骤①：tab为空则创建
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        // 步骤②：计算index，并对null做处理
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            // 步骤③：节点key存在，直接覆盖value
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            // 步骤④：判断该链为红黑树
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            // 步骤⑤：该链为链表
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        //链表长度大于8转换为红黑树进行处理
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    // key已经存在直接覆盖value
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        // 步骤⑥：超过最大容量 就扩容
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }

```
### 树化
```java
final void treeifyBin(Node<K,V>[] tab, int hash) {
        int n, index; Node<K,V> e;
        if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY)
            resize();
        else if ((e = tab[index = (n - 1) & hash]) != null) {
            TreeNode<K,V> hd = null, tl = null;
            do {
                TreeNode<K,V> p = replacementTreeNode(e, null);
                if (tl == null)
                    hd = p;
                else {
                    p.prev = tl;
                    tl.next = p;
                }
                tl = p;
            } while ((e = e.next) != null);
            if ((tab[index] = hd) != null)
                hd.treeify(tab);
        }
    }
    final void treeify(Node<K,V>[] tab) {
            TreeNode<K,V> root = null;
            for (TreeNode<K,V> x = this, next; x != null; x = next) {
                next = (TreeNode<K,V>)x.next;
                x.left = x.right = null;
                if (root == null) {
                    x.parent = null;
                    x.red = false;
                    root = x;
                }
                else {
                    K k = x.key;
                    int h = x.hash;
                    Class<?> kc = null;
                    for (TreeNode<K,V> p = root;;) {
                        int dir, ph;
                        K pk = p.key;
                        if ((ph = p.hash) > h)
                            dir = -1;
                        else if (ph < h)
                            dir = 1;
                        else if ((kc == null &&
                                  (kc = comparableClassFor(k)) == null) ||
                                 (dir = compareComparables(kc, k, pk)) == 0)
                            dir = tieBreakOrder(k, pk);

                        TreeNode<K,V> xp = p;
                        if ((p = (dir <= 0) ? p.left : p.right) == null) {
                            x.parent = xp;
                            if (dir <= 0)
                                xp.left = x;
                            else
                                xp.right = x;
                            root = balanceInsertion(root, x);
                            break;
                        }
                    }
                }
            }
            moveRootToFront(tab, root);
        }
```

### 扩容过程

- 扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素



- 当然Java里的数组是无法自动扩容的，方法是使用一个新的数组代替已有的容量小的数组，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶

- 我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我先使用JDK1.7的代码，好理解一些，再分析1.8的源码，本质上区别不大，先贴jdk 1.7的源码如下：

```java
//传入新的容量
void resize(int newCapacity) {
	//引用扩容前的Entry数组
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    //扩容前的数组大小如果已经达到最大(2^30)了
    if (oldCapacity == MAXIMUM_CAPACITY) {
    	//修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了
        threshold = Integer.MAX_VALUE;
        return;
    }
    //初始化一个新的Entry数组
    Entry[] newTable = new Entry[newCapacity];
    //将数据转移到新的Entry数组里，见下一个方法
    transfer(newTable);
    //HashMap的table属性引用新的Entry数组
    table = newTable;
    //修改阈值
    threshold = (int)(newCapacity * loadFactor);
}
void transfer(Entry[] newTable) {
	Entry[] src = table;                   //src引用了旧的Entry数组
	int newCapacity = newTable.length;
	for (int j = 0; j < src.length; j++) { //遍历旧的Entry数组
		Entry<K,V> e = src[j];             //取得旧Entry数组的每个元素
		if (e != null) {
        	//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）
			src[j] = null;
				do {
					Entry<K,V> next = e.next;
                    //重新计算每个元素在数组中的位置
					int i = indexFor(e.hash, newCapacity);
                    //标记[1]
					e.next = newTable[i];
                    //将元素放在数组上
					newTable[i] = e;
                    //访问下一个Entry链上的元素
					e = next;
				} while (e != null);
		}
	}
}
static int indexFor(int h, int length) {
     return h & (length-1);
}
```

- newTable[i]的引用赋给了e.next，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置；

- 这样先放在一个索引上的元素终会被放到Entry链的尾部(如果发生了hash冲突的话），这一点和Jdk1.8有区别；

- 在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上；

- 下面举个例子说明下扩容过程。

	- 假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）

	- 其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3

	- 在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容

	- 接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程

	![jdk1.7扩容例图](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/jdk1.7扩容例图.png)

- JDK1.8的`resize()`源码如下：

```java

final Node<K,V>[] resize() {

        Node<K,V>[] oldTab = table;

        int oldCap = (oldTab == null) ? 0 : oldTab.length;

        int oldThr = threshold;

        int newCap, newThr = 0;

        if (oldCap > 0) {

            if (oldCap >= MAXIMUM_CAPACITY) {

                threshold = Integer.MAX_VALUE;

                return oldTab;

            }

            else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&

                     oldCap >= DEFAULT_INITIAL_CAPACITY)

                newThr = oldThr << 1; // double threshold

        }

        else if (oldThr > 0)

            newCap = oldThr;

        else {

            newCap = DEFAULT_INITIAL_CAPACITY;

            newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);

        }

        if (newThr == 0) {

            float ft = (float)newCap * loadFactor;

            newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ?

                      (int)ft : Integer.MAX_VALUE);

        }

        threshold = newThr;

        @SuppressWarnings({"rawtypes","unchecked"})

            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];

        table = newTab;

        if (oldTab != null) {

            for (int j = 0; j < oldCap; ++j) {

                Node<K,V> e;

                if ((e = oldTab[j]) != null) {

                    oldTab[j] = null;

                    if (e.next == null)

                        newTab[e.hash & (newCap - 1)] = e;

                    else if (e instanceof TreeNode)

                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);

                    else { // preserve order

                        Node<K,V> loHead = null, loTail = null;

                        Node<K,V> hiHead = null, hiTail = null;

                        Node<K,V> next;

                        do {

                            next = e.next;

                            if ((e.hash & oldCap) == 0) {

                                if (loTail == null)

                                    loHead = e;

                                else

                                    loTail.next = e;

                                loTail = e;

                            }

                            else {

                                if (hiTail == null)

                                    hiHead = e;

                                else

                                    hiTail.next = e;

                                hiTail = e;

                            }

                        } while ((e = next) != null);

                        if (loTail != null) {

                            loTail.next = null;

                            newTab[j] = loHead;

                        }

                        if (hiTail != null) {

                            hiTail.next = null;

                            newTab[j + oldCap] = hiHead;

                        }

                    }

                }

            }

        }

        return newTab;

    }

```



- JDK1.8做了一些优化工作

	- 经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置，如下图：

	![hashMap 1.8 哈希算法例图1](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap 1.8 哈希算法例图1.png)

    - n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果

    - 元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：

    ![hashMap 1.8 哈希算法例图2](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap 1.8 哈希算法例图2.png)

    - 扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”，可以看看下图为16扩充为32的resize示意图：

    ![jdk1.8 hashMap扩容例图](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/jdk1.8 hashMap扩容例图.png)

    - 这样设计既省去了重新计算hash值的时间，而且同时，由于新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket

    - 这一块就是JDK1.8新增的优化点。有一点注意区别，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置

    - 当链表长度大于默认值8时会树化，源码如下：

```java

final void treeify(Node<K,V>[] tab) {

            TreeNode<K,V> root = null;

            for (TreeNode<K,V> x = this, next; x != null; x = next) {

                next = (TreeNode<K,V>)x.next;

                x.left = x.right = null;

                if (root == null) {

                    x.parent = null;

                    x.red = false;

                    root = x;

                }

                else {

                    K k = x.key;

                    int h = x.hash;

                    Class<?> kc = null;

                    for (TreeNode<K,V> p = root;;) {

                        int dir, ph;

                        K pk = p.key;

                        if ((ph = p.hash) > h)

                            dir = -1;

                        else if (ph < h)

                            dir = 1;

                        else if ((kc == null &&

                                  (kc = comparableClassFor(k)) == null) ||

                                 (dir = compareComparables(kc, k, pk)) == 0)

                            dir = tieBreakOrder(k, pk);



                        TreeNode<K,V> xp = p;

                        if ((p = (dir <= 0) ? p.left : p.right) == null) {

                            x.parent = xp;

                            if (dir <= 0)

                                xp.left = x;

                            else

                                xp.right = x;

                            root = balanceInsertion(root, x);

                            break;

                        }

                    }

                }

            }

            moveRootToFront(tab, root);

        }

        //当元素个数小于等于static final int UNTREEIFY_THRESHOLD = 6;时，就会反树化

        final Node<K,V> untreeify(HashMap<K,V> map) {

            Node<K,V> hd = null, tl = null;

            for (Node<K,V> q = this; q != null; q = q.next) {

                Node<K,V> p = map.replacementNode(q, null);

                if (tl == null)

                    hd = p;

                else

                    tl.next = p;

                tl = p;

            }

            return hd;

        }

```



### 线程安全性

- 在多线程使用场景中，应该尽量避免使用线程不安全的HashMap，而使用线程安全的ConcurrentHashMap。因为多线程环境下，HashMap可能导致死循环。举例说明如下：

```java

public class HashMapInfiniteLoop {

    private static HashMap<Integer,String> map = new HashMap<Integer,String>(2，0.75f);

    public static void main(String[] args) {

        map.put(5， "C");

        new Thread("Thread1") {

            public void run() {

                map.put(7, "B");

                System.out.println(map);

            };

        }.start();

        new Thread("Thread2") {

            public void run() {

                map.put(3, "A);

                System.out.println(map);

            };

        }.start();

    }

}

```

其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize，源码如下：

```java

final Node<K,V>[] resize() {

        ...

        @SuppressWarnings({"rawtypes","unchecked"})

            Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];

        table = newTab;

        if (oldTab != null) {

            for (int j = 0; j < oldCap; ++j) {

                Node<K,V> e;

                if ((e = oldTab[j]) != null) {

                    oldTab[j] = null;

                    if (e.next == null)

                    	//③

                        newTab[e.hash & (newCap - 1)] = e;

                    else if (e instanceof TreeNode)

                        ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);

                    else { // preserve order

                        Node<K,V> loHead = null, loTail = null;

                        Node<K,V> hiHead = null, hiTail = null;

                        Node<K,V> next;

                        do {

                        	//断点标记①

                            next = e.next;

                            if ((e.hash & oldCap) == 0) {

                                if (loTail == null)

                                    loHead = e;

                                else

                                    loTail.next = e;

                                loTail = e;

                            }

                            else {

                                if (hiTail == null)

                                    hiHead = e;

                                else

                                    hiTail.next = e;

                                hiTail = e;

                            }

                        } while ((e = next) != null);

                        if (loTail != null) {

                            loTail.next = null;

                            newTab[j] = loHead;

                        }

                        if (hiTail != null) {

                            hiTail.next = null;

                            newTab[j + oldCap] = hiHead;

                        }

                    }

                }

            }

        }

        return newTab;

    }

```

	① 两个线程在put的过程中都会进行扩容。此时，一旦线程1在执行扩容过程中，执行到断点标记处，被CPU调度挂起，从e指向key=3,next指向key=7，到线程2执行完扩容全过程，旧数组指向空，就会发生下图的情形：

![hashMap死循环例图1](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap死循环例图1.png)

	② 此时，线程1中e仍然指向key=3，next仍然指向key=7），如下图：

![hashMap死循环例图2](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap死循环例图2.png)

	③ 线程1被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key=7，而下一次循环的next = e.next导致了next指向了key=3，如下图：

![hashMap死循环例图3](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap死循环例图3.png)

	④e.next = newTable[i] 导致 (key=3).next 指向了 (key=7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现，如下图所示：

![hashMap死循环例图4](https://github.com/heshengbang/heshengbang.github.io/raw/master/images/javabasic/hashMap死循环例图4.png)



### JDK1.8与JDK1.7的性能对比

- HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)

- 如果Hash算法技术的结果碰撞非常多，假如Hash算法极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。



### 小结

- 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。

- 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。

- HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。

- JDK1.8引入红黑树大程度优化了HashMap的性能。

- 还没升级JDK1.8的，现在开始升级吧。HashMap的性能提升仅仅是JDK1.8的冰山一角。



## 扩展

### 解决哈希冲突的常用方法有：

- 开放定址法

基本思想：当发生地址冲突时，按照某种方法继续探测哈希表中的其他存储单元，直到找到空位置为止。

这个过程可用下式描述：

p=(p+di) mod m (i=1,2,…… ，k ( k ≤ m – 1))

其中：p为关键字key的直接哈希地址，m为哈希表的长度，di 为每次再探测时的地址增量。采用这种方法时，首先计算出元素的直接哈希地址p ，如果该存储单元已被其他元素占用，则继续查看地址为p + d1 的存储单元，如此重复直至找到某个存储单元为空时，将关键字为 key 的数据元素存放到该单元。增量 d 可以有不同的取法，并根据其取法有不同的称呼：线性探测再散列、二次探测再散列、伪随机序列/伪随机再散列

- 再哈希法

基本思想：这种方法是同时构造多个不同的哈希函数。p=RHi(key) (i=1，2，…，k)，当哈希地址p=RH1(key)发生冲突时，再计算p=RH2(key)……，直到冲突不再产生。这种方法不易产生聚集，但增加了计算时间。

- 链地址法

基本思想：将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第i个单元中，因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。（HashMap采用了此办法）

- 建立公共溢出区

基本思想是：将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。

### 红黑树



未完待续...

本文高度参考[重新认识HashMap](https://tech.meituan.com/java-hashmap.html)，感谢原作者的辛苦劳动。手动鞠躬，侵删。